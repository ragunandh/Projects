{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b9bd22-6078-46fd-9743-9aee964d0630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: E:\\insurance1.pdf\n",
      "Processing: E:\\insurance2.pdf\n",
      "Processing: E:\\insurance3.pdf\n",
      "Processing: E:\\insurance4.pdf\n",
      "Processing: E:\\insurance5.pdf\n",
      "Extraction complete. Text saved in E:\\extracted_text.txt\n",
      "Successfully processed 5 files\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_text_from_pdfs(pdf_files, output_file):\n",
    "    extracted_data = {}\n",
    "    \n",
    "    # Convert output_file to Path object\n",
    "    output_path = Path(output_file)\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for pdf_path in pdf_files:\n",
    "        try:\n",
    "            # Convert pdf_path to Path object\n",
    "            pdf_path = Path(pdf_path)\n",
    "            \n",
    "            if not pdf_path.exists():\n",
    "                print(f\"File not found: {pdf_path}\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"Processing: {pdf_path}\")\n",
    "            \n",
    "            with pdfplumber.open(str(pdf_path)) as pdf:\n",
    "                text = \"\"\n",
    "                for page in pdf.pages:\n",
    "                    # Extract text with better handling of layout\n",
    "                    extracted_text = page.extract_text(x_tolerance=3, y_tolerance=3)\n",
    "                    if extracted_text:\n",
    "                        text += extracted_text + \"\\n\"\n",
    "                \n",
    "                # Store extracted text if not empty\n",
    "                if text.strip():\n",
    "                    extracted_data[str(pdf_path)] = text\n",
    "                else:\n",
    "                    print(f\"No text extracted from: {pdf_path}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdf_path}: {str(e)}\")\n",
    "    \n",
    "    # Save extracted text into a text file\n",
    "    try:\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as out_file:\n",
    "            for pdf_name, pdf_text in extracted_data.items():\n",
    "                out_file.write(f\"File: {pdf_name}\\n\")\n",
    "                out_file.write(pdf_text)\n",
    "                out_file.write(\"\\n\" + \"=\"*80 + \"\\n\")  # Separator\n",
    "        \n",
    "        if extracted_data:\n",
    "            print(f\"Extraction complete. Text saved in {output_path}\")\n",
    "            print(f\"Successfully processed {len(extracted_data)} files\")\n",
    "        else:\n",
    "            print(\"No text was extracted from any of the PDF files\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving output file: {str(e)}\")\n",
    "\n",
    "# Example usage with proper Windows paths\n",
    "if __name__ == \"__main__\":\n",
    "    # Using raw strings and proper Windows path format\n",
    "    pdf_files = [\n",
    "        r\"E:\\insurance1.pdf\",\n",
    "        r\"E:\\insurance2.pdf\",\n",
    "        r\"E:\\insurance3.pdf\",\n",
    "        r\"E:\\insurance4.pdf\",\n",
    "        r\"E:\\insurance5.pdf\"\n",
    "    ]\n",
    "    output_file = r\"E:\\extracted_text.txt\"\n",
    "    \n",
    "    # First make sure you have pdfplumber installed\n",
    "    try:\n",
    "        import pdfplumber\n",
    "    except ImportError:\n",
    "        print(\"pdfplumber is not installed. Installing it now...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call(['pip', 'install', 'pdfplumber'])\n",
    "        print(\"pdfplumber has been installed successfully!\")\n",
    "    \n",
    "    try:\n",
    "        # Test if we can write to the output directory\n",
    "        test_file = Path(output_file).parent / \"test_write_permission.txt\"\n",
    "        test_file.touch()\n",
    "        test_file.unlink()  # Delete the test file\n",
    "        \n",
    "        # If we get here, we have write permissions\n",
    "        extract_text_from_pdfs(pdf_files, output_file)\n",
    "        \n",
    "    except PermissionError:\n",
    "        print(f\"Error: No permission to write to directory {Path(output_file).parent}\")\n",
    "        print(\"Please run the script with appropriate permissions or choose a different output location\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6785ff37-f502-411a-b1bc-b7d951443951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to E:\\insurance_details.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_details_from_text(text):\n",
    "    # Dictionary to store extracted details\n",
    "    details = {}\n",
    "    \n",
    "    # Extract Name\n",
    "    name_match = re.search(r'Greetings\\s+(\\w+)', text)\n",
    "    details['Name'] = name_match.group(1) if name_match else ''\n",
    "    \n",
    "    # Extract Policy Name\n",
    "    policy_match = re.search(r'([\\w\\s]+Health Insurance)\\s+\\d{2}-\\d{2}-\\d{4}', text)\n",
    "    details['Policy Name'] = policy_match.group(1).strip() if policy_match else ''\n",
    "    \n",
    "    # Extract Policy Period\n",
    "    period_match = re.search(r'(\\d{2}-\\d{2}-\\d{4}\\s+to\\s+\\d{2}\\s+-\\d{2}-\\d{4})', text)\n",
    "    details['Policy Period'] = period_match.group(1) if period_match else ''\n",
    "    \n",
    "    # Extract Gender\n",
    "    gender_match = re.search(r'(\\w+)\\s+Self', text)\n",
    "    details['Gender'] = gender_match.group(1) if gender_match else ''\n",
    "    \n",
    "    # Extract Email\n",
    "    email_match = re.search(r'(\\S+@\\S+\\.\\S+)\\s', text.replace(' ', ''))\n",
    "    details['Email Address'] = email_match.group(1) if email_match else ''\n",
    "    \n",
    "    # Extract DOB\n",
    "    dob_match = re.search(r'(\\d{2}-\\d{2}-\\d{4})\\s+-', text)\n",
    "    details['DOB'] = dob_match.group(1) if dob_match else ''\n",
    "    \n",
    "    # Extract Enrollment Date\n",
    "    enrollment_match = re.search(r'confirmed on (\\d{2}\\s+-\\d{2}-\\d{4}\\s+\\d{2}:\\d{2}:\\d{2})', text)\n",
    "    details['Enrollment Confirmed on'] = enrollment_match.group(1) if enrollment_match else ''\n",
    "    \n",
    "    # Extract Family Cover\n",
    "    cover_match = re.search(r'Family\\s+Cover\\s+(\\d{1,2},\\d{2},\\d{3})', text)\n",
    "    details['Family Cover'] = cover_match.group(1) if cover_match else ''\n",
    "    \n",
    "    return details\n",
    "\n",
    "def process_text_file_to_csv(input_file, output_csv):\n",
    "    # Read the input file\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Split content by the separator\n",
    "    pdf_contents = content.split('=' * 80)\n",
    "    \n",
    "    # Prepare data for CSV\n",
    "    all_records = []\n",
    "    \n",
    "    # Process each PDF content\n",
    "    for pdf_content in pdf_contents:\n",
    "        if pdf_content.strip():  # Skip empty sections\n",
    "            details = extract_details_from_text(pdf_content)\n",
    "            if details['Name']:  # Only add if we found a name (valid entry)\n",
    "                all_records.append(details)\n",
    "    \n",
    "    # Write to CSV\n",
    "    if all_records:\n",
    "        fieldnames = ['Name', 'Policy Name', 'Policy Period', 'Gender', \n",
    "                     'Email Address', 'DOB', 'Enrollment Confirmed on', 'Family Cover']\n",
    "        \n",
    "        with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_records)\n",
    "        print(f\"Data successfully written to {output_csv}\")\n",
    "    else:\n",
    "        print(\"No records found to write to CSV\")\n",
    "\n",
    "# Example usage\n",
    "input_file = r\"E:\\extracted_text.txt\"\n",
    "output_csv = r\"E:\\insurance_details.csv\"\n",
    "process_text_file_to_csv(input_file, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c3b7e2-edda-40c6-8e85-72a974763c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
